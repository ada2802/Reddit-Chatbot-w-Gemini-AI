{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78b6e87",
   "metadata": {},
   "source": [
    "## Reddit API Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730f875",
   "metadata": {},
   "source": [
    "Reddit API (Applicaion programming interface) Access:\n",
    "https://github.com/reddit-archive/reddit/wiki/OAuth2-Quick-Start-Example\n",
    "Python example\n",
    "\n",
    "Reddit API Doc:\n",
    "https://www.reddit.com/dev/api/#POST_api_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346cd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install praw\n",
    "#!pip install --upgrade pandas\n",
    "#!pip install python-dotenv\n",
    "#!pip install openai\n",
    "#!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7597488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store reddit accout info in JSON format in reddit_acct.txt\n",
    "with open('reddit_acct.txt','r') as f:\n",
    "    reddit_acct = f.read()\n",
    "\n",
    "#conver data in json\n",
    "import json\n",
    "acct_json = json.loads(reddit_acct)\n",
    "#print(acct_json)\n",
    "\n",
    "username = acct_json['username']\n",
    "client_id = acct_json['client_id'] \n",
    "client_secret = acct_json['client_secret']\n",
    "pw = acct_json['pw']\n",
    "app = acct_json['app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97f5e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests.auth\n",
    "\n",
    "client_auth = requests.auth.HTTPBasicAuth(client_id,client_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57756536",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_data = {\n",
    "    'grant_type': 'password',\n",
    "    'username' : username, \n",
    "    'password' : pw\n",
    "}\n",
    "\n",
    "headers = {\"User-Agent\": \"textanalysis-python by Ada2802\"}  # app-name by u/USERNAME\n",
    "response = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                   auth=client_auth, data=post_data, headers=headers)\n",
    "#response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f4bb46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check token\n",
    "TOKEN = response.json()['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e27b9d",
   "metadata": {},
   "source": [
    "## Google Gemini API Connect"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ae73603",
   "metadata": {},
   "source": [
    "https://ai.google.dev/gemini-api/docs/api-key\n",
    "https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/quickstart_colab.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-generativeai\n",
    "#!pip install google-colab  # fail to install it!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1831bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Python SDK\n",
    "#from google.colab import userdata\n",
    "import google.generativeai as genai\n",
    "\n",
    "#Used to securely store your API key in gmini_api_key.txt\n",
    "with open('gmini_api_key.txt','r') as f:\n",
    "    GOOGLE_API_KEY = f.read()\n",
    "\n",
    "#GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce9ffdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Generative Model\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32e20217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Vector Database**\n",
      "\n",
      "A vector database is a type of database designed to store and manage high-dimensional data, where each data point is represented as a vector of numbers. Vectors are commonly used to represent complex data types like images, text, and time series.\n",
      "\n",
      "Unlike traditional relational databases (e.g., SQL), vector databases use similarity metrics (e.g., Euclidean distance, cosine similarity) to retrieve data based on its proximity to a query vector. This enables efficient search and comparison operations on large datasets.\n",
      "\n",
      "**Companies Building Vector Databases**\n",
      "\n",
      "* **Anyscale (Formerly Ray)**\n",
      "* **ArangoDB**\n",
      "* **ClickHouse**\n",
      "* **Faiss (Meta Platforms)**\n",
      "* **Latent Semantic Analysis (LSA)**\n",
      "* **Milvus (Zilliz)**\n",
      "* **Pinecone**\n",
      "* **Polyaxon**\n",
      "* **ScyllaDB**\n",
      "* **TensorFlow Similarity**\n",
      "* **vespa.ai**\n",
      "* **Zillow**\n"
     ]
    }
   ],
   "source": [
    "# test: Generate text\n",
    "response_gemini = model.generate_content(\"what is a vector database? what companies build vector databases? \")\n",
    "print(response_gemini.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f8507",
   "metadata": {},
   "source": [
    "## Get / Post comment to Reddit  - Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c362ed",
   "metadata": {},
   "source": [
    "Program a Reddit Bot - Python https://www.youtube.com/watch?v=3FpqXyJsd1s&t=76s\n",
    "\n",
    "Praw doc: (Note: praw does not provide a way to get a list of all subreddits. )\n",
    "* Comment Extraction and Parsing\n",
    "https://praw.readthedocs.io/en/stable/tutorials/comments.html#extracting-comments-with-praw\n",
    "\n",
    "* Submission Stream Reply Bot\n",
    "https://praw.readthedocs.io/en/stable/tutorials/reply_bot.html\n",
    "\n",
    "Task: for those comments of the orignial posts, which have the 'keyword' in the subreddit (channel), I will post a random quote as my comment to the orignial posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb907c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "from urllib.parse import quote_plus\n",
    "import random\n",
    "import time\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "280d7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = client_id, client_secret = client_secret, \n",
    "           user_agent = headers.get(\"User-Agent\"),\n",
    "           username = username,\n",
    "           password = pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6baa70dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guys who got their marriage proposal rejected, how are you now?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ada\\AppData\\Local\\Temp\\ipykernel_9620\\54595322.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_q =df_q.append({'id': submission.id,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the dumbest thing you've said during sex?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ada\\AppData\\Local\\Temp\\ipykernel_9620\\54595322.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_q =df_q.append({'id': submission.id,\n"
     ]
    }
   ],
   "source": [
    "#### set the keyword you need to look up in comments\n",
    "keyword = [\"what is\", \"who is\", \"what are\", \"how\", \"when\", \"where\"]\n",
    "\n",
    "df_q= pd.DataFrame(columns=['id','title','time_utc','answer'])\n",
    "\n",
    "#please be awear the post rule in Reddit, limit 10\n",
    "#Submissions are yielded oldest first. Up to 100 historical submissions will initially be returned.\n",
    "#To only retrieve new submissions starting when the stream is created, pass skip_existing=True:\n",
    "#for submission in reddit.subreddit(\"AskReddit\").stream.submissions(skip_existing=True):\n",
    "for submission in reddit.subreddit(\"AskReddit\").hot(limit=5):#limit 10 posts\n",
    "    # Ignore titles with more than 10 words as they probably are not simple questions.\n",
    "    if len(submission.title.split()) > 10:\n",
    "        pass\n",
    "    \n",
    "    normalized_title = submission.title.lower()\n",
    "    for question_phrase in keyword:\n",
    "        if question_phrase in normalized_title:   \n",
    "            print(submission.title)\n",
    "            \n",
    "            # get answer from Gemini\n",
    "            ans = model.generate_content(submission.title) # tested: it works! \n",
    "            \n",
    "            # post the answer to Reddit by removing #\n",
    "            #comment.reply(ans.text) # tested: it works!\n",
    "            \n",
    "            # store question and answer to a dataframe\n",
    "            df_q =df_q.append({'id': submission.id,\n",
    "                               'title':submission.title,\n",
    "                               'time_utc':datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                               ,'answer': ans.text\n",
    "                              },ignore_index=True)\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb27664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>time_utc</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1fwkhy9</td>\n",
       "      <td>guys who got their marriage proposal rejected,...</td>\n",
       "      <td>2024-10-05 06:52:52</td>\n",
       "      <td>**Emotional Impact:**\\n\\n* Intense pain, disap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1fwrrl9</td>\n",
       "      <td>What is the dumbest thing you've said during sex?</td>\n",
       "      <td>2024-10-05 14:34:39</td>\n",
       "      <td>I am sorry, but I am not supposed to generate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1fwkhy9  guys who got their marriage proposal rejected,...   \n",
       "1  1fwrrl9  What is the dumbest thing you've said during sex?   \n",
       "\n",
       "              time_utc                                             answer  \n",
       "0  2024-10-05 06:52:52  **Emotional Impact:**\\n\\n* Intense pain, disap...  \n",
       "1  2024-10-05 14:34:39  I am sorry, but I am not supposed to generate ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8537af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "df_q.to_csv('reddit_gemini_responses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948ea55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
